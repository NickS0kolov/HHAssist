from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(BASE_DIR, ".env")
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path)

model_name = os.getenv("OLLAMA_MODEL")
model = OllamaLLM(model=model_name, base_url=os.getenv("OLLAMA_BASE_URL"))

# === –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ ===
async def analyze_resume(resume_text: str, job_description: str) -> str:
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
–¢—ã ‚Äî –∫–∞—Ä—å–µ—Ä–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–æ–∑–¥–∞—é—â–∏–π –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è Telegram.
–°—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π —Ñ–æ—Ä–º–∞—Ç. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown, HTML, –∫–∞–≤—ã—á–∫–∏ –∏ –∑–Ω–∞–∫ *.
–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤, –∏–º—ë–Ω, –Ω–∞–≤—ã–∫–æ–≤ –∏–ª–∏ –∫–æ–º–ø–∞–Ω–∏–π.
–†–∞–±–æ—Ç–∞–π —Ç–æ–ª—å–∫–æ —Å —Ç–µ–∫—Å—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—ë—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å. –ù–µ –ø—Ä–µ–≤—ã—à–∞–π 1000 —Å–∏–º–≤–æ–ª–æ–≤.
–ï—Å–ª–∏ –≤ —Ä–µ–∑—é–º–µ –µ—Å—Ç—å –∏–º—è, –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π.
–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –∏ –Ω–µ –º–µ–Ω—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
"""),

        ("human", """
–û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ–∑—é–º–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –≤—ã–¥–∞–π –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —Ñ–æ—Ä–º–µ:

üìã –°–æ–≤–ø–∞–¥–µ–Ω–∏—è:
(2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—É–Ω–∫—Ç–∞)

‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞–µ—Ç:
(2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—É–Ω–∫—Ç–∞)

üéØ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: XX%

üí° –°–æ–≤–µ—Ç—ã:
(–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑ 3‚Äì4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)

‚úâÔ∏è –°–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ:
(2‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–±–∑–∞—Ü–∞, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ)

–†–µ–∑—é–º–µ:
{resume_text}

–í–∞–∫–∞–Ω—Å–∏—è:
{job_description}
""")
    ])

    chain = prompt | model
    result = await chain.ainvoke({
        "resume_text": resume_text,
        "job_description": job_description
    })
    return result

# === –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ===
async def analyze_message(resume_text: str, job_description: str, question: str) -> str:
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É —Ä–∞–±–æ—Ç—ã. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —Ç–µ–∫—Å—Ç—É —Ä–µ–∑—é–º–µ, –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –≤–æ–ø—Ä–æ—Å–∞.
–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown, HTML, –∫–∞–≤—ã—á–∫–∏ –∏ –∑–Ω–∞–∫ *. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, –∏–º–µ–Ω–∞ –∏–ª–∏ –Ω–∞–≤—ã–∫–∏.
–ù–µ –ø–æ–¥–±–∏—Ä–∞–π –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏.
"""),

        ("human", """
–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ 1250 —Å–∏–º–≤–æ–ª–æ–≤.

–†–µ–∑—é–º–µ:
{resume_text}

–í–∞–∫–∞–Ω—Å–∏—è:
{job_description}

–í–æ–ø—Ä–æ—Å:
{question}

–¢–µ–ø–µ—Ä—å –¥–∞–π –æ—Ç–≤–µ—Ç.
""")
    ])

    chain = prompt | model
    result = await chain.ainvoke({
        "resume_text": resume_text,
        "job_description": job_description,
        "question": question
    })
    return result